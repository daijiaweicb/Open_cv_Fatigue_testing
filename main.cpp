#include <iostream>
#include <opencv2/opencv.hpp>
#include <dlib/opencv.h>
#include <dlib/image_processing.h>
#include <atomic>
#include <mutex>
#include <signal.h>
#include <thread>
#include "libcam2opencv.h"

// å…¨å±€å˜é‡
std::atomic<bool> g_running(true);
std::mutex frame_mutex;

// ä¿¡å·å¤„ç†å‡½æ•°
void signal_handler(int signal) {
    std::cout << "æ¥æ”¶åˆ°ä¿¡å·: " << signal << "ï¼Œå‡†å¤‡ä¼˜é›…é€€å‡º" << std::endl;
    g_running = false;
}

// çœ¼ç›çºµæ¨ªæ¯”è®¡ç®—
float eye_aspect_ratio(const std::vector<cv::Point2f>& eye) {
    float A = cv::norm(eye[1] - eye[5]);
    float B = cv::norm(eye[2] - eye[4]);
    float C = cv::norm(eye[0] - eye[3]);
    return (A + B) / (2.0f * C);
}

// æå–çœ¼ç›å…³é”®ç‚¹
std::vector<cv::Point2f> extract_eye(const dlib::full_object_detection& shape, bool left) {
    std::vector<cv::Point2f> eye;
    int start = left ? 36 : 42;
    for (int i = 0; i < 6; ++i)
        eye.emplace_back(shape.part(start + i).x(), shape.part(start + i).y());
    return eye;
}

// å›è°ƒç±»å®ç°
class FatigueCallback : public Libcam2OpenCV::Callback {
public:
    FatigueCallback() : 
        frame_counter(0), 
        total_frames(0),
        fps(0),
        last_log_time(0),
        dlib_loaded(false),
        haar_loaded(false) {
        
        // åˆå§‹è®¡æ—¶
        start_time = std::chrono::steady_clock::now();
        
        // å°è¯•åŠ è½½ dlib å…³é”®ç‚¹æ¨¡å‹
        try {
            dlib::deserialize("shape_predictor_68_face_landmarks.dat") >> predictor;
            std::cout << "âœ… æˆåŠŸåŠ è½½é¢éƒ¨å…³é”®ç‚¹æ¨¡å‹" << std::endl;
            dlib_loaded = true;
        } catch (std::exception& e) {
            std::cerr << "âŒ æ— æ³•åŠ è½½å…³é”®ç‚¹æ¨¡å‹ï¼š" << e.what() << std::endl;
            std::cerr << "å°†ç»§ç»­è¿è¡Œä½†ä¸è¿›è¡Œç–²åŠ³æ£€æµ‹" << std::endl;
        }

        // å°è¯•åŠ è½½ Haar äººè„¸æ£€æµ‹å™¨
        if (face_cascade.load("/usr/share/opencv4/haarcascades/haarcascade_frontalface_default.xml")) {
            std::cout << "âœ… æˆåŠŸåŠ è½½äººè„¸æ£€æµ‹å™¨" << std::endl;
            haar_loaded = true;
        } else {
            std::cerr << "âŒ æ— æ³•åŠ è½½ Haar æ¨¡å‹" << std::endl;
            std::cerr << "å°†ç»§ç»­è¿è¡Œä½†ä¸è¿›è¡Œäººè„¸æ£€æµ‹" << std::endl;
        }
        
        // åˆ›å»ºçª—å£
        cv::namedWindow("æ‘„åƒå¤´æµ‹è¯•", cv::WINDOW_NORMAL);
        cv::resizeWindow("æ‘„åƒå¤´æµ‹è¯•", 800, 600);
        std::cout << "âœ… åˆå§‹åŒ–å®Œæˆï¼Œç­‰å¾…æ‘„åƒå¤´å¸§..." << std::endl;
    }
    
    ~FatigueCallback() {
        std::cout << "é”€æ¯å›è°ƒå¯¹è±¡ï¼Œæ¸…ç†èµ„æº..." << std::endl;
        cv::destroyAllWindows();
    }

    void hasFrame(const cv::Mat &frame, const libcamera::ControlList &metadata) override {
        // æ¯æ¬¡æ”¶åˆ°å¸§æ—¶è®°å½•æ—¥å¿—
        total_frames++;
        if (total_frames <= 5 || total_frames % 30 == 0) {
            std::cout << "ğŸ“· æ”¶åˆ°å¸§ #" << total_frames << " å¤§å°: " << 
                frame.cols << "x" << frame.rows << " ç±»å‹: " << frame.type() << std::endl;
        }
        
        // å¸§è®¡æ•°å™¨å¢åŠ 
        frame_counter++;
        
        // è®¡ç®—å½“å‰æ—¶é—´å’Œç»è¿‡çš„æ—¶é—´
        auto current_time = std::chrono::steady_clock::now();
        auto elapsed = std::chrono::duration_cast<std::chrono::milliseconds>(
            current_time - start_time).count();
        
        // è®¡ç®—FPS (æ¯ç§’æ›´æ–°ä¸€æ¬¡)
        if (elapsed >= 1000) {  // æ¯ç§’æ›´æ–°ä¸€æ¬¡
            fps = static_cast<float>(frame_counter) * 1000.0f / elapsed;
            std::cout << "â±ï¸ FPSè®¡ç®—: " << frame_counter << " å¸§åœ¨ " << 
                elapsed << " æ¯«ç§’ = " << fps << " FPS" << std::endl;
            
            frame_counter = 0;
            start_time = current_time;
            
            // è®°å½•åˆ°æ§åˆ¶å° (æ¯5ç§’)
            auto now = std::time(nullptr);
            if (now - last_log_time >= 5) {
                std::cout << "ğŸ“Š å½“å‰FPS: " << fps << " æ€»å¸§æ•°: " << total_frames << std::endl;
                last_log_time = now;
            }
        }

        // åˆ›å»ºä¸€ä¸ªå·¥ä½œå‰¯æœ¬
        cv::Mat display_frame = frame.clone();
        
        // ç¡®ä¿å¸§æœ‰æ•ˆ
        if (display_frame.empty()) {
            std::cerr << "âŒ æ”¶åˆ°ç©ºå¸§ï¼" << std::endl;
            return;
        }

        // æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        std::string fps_text = "FPS: " + std::to_string(fps).substr(0, fps > 0 ? 5 : 1);
        cv::putText(display_frame, fps_text, cv::Point(10, 30),
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);
                   
        // æ˜¾ç¤ºå¸§è®¡æ•°
        cv::putText(display_frame, "Frame: " + std::to_string(total_frames), 
                   cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.7, 
                   cv::Scalar(0, 255, 0), 2);

        // åªæœ‰å½“ä¸¤ä¸ªæ¨¡å‹éƒ½åŠ è½½æˆåŠŸæ—¶æ‰è¿›è¡Œç–²åŠ³æ£€æµ‹
        if (dlib_loaded && haar_loaded) {
            try {
                // è½¬ç°åº¦å›¾è¿›è¡Œäººè„¸æ£€æµ‹
                cv::Mat gray;
                cv::cvtColor(display_frame, gray, cv::COLOR_BGR2GRAY);

                // äººè„¸æ£€æµ‹
                std::vector<cv::Rect> faces;
                face_cascade.detectMultiScale(gray, faces, 1.1, 3, 0, cv::Size(80, 80));
                
                if (!faces.empty()) {
                    cv::putText(display_frame, "Faces: " + std::to_string(faces.size()),
                           cv::Point(10, 90), cv::FONT_HERSHEY_SIMPLEX, 0.7, 
                           cv::Scalar(0, 255, 0), 2);
                }

                for (const auto& face : faces) {
                    cv::rectangle(display_frame, face, cv::Scalar(255, 0, 0), 2);

                    try {
                        dlib::cv_image<dlib::bgr_pixel> cimg(display_frame);
                        dlib::rectangle dlib_rect(face.x, face.y, face.x + face.width, face.y + face.height);
                        dlib::full_object_detection shape = predictor(cimg, dlib_rect);

                        auto left_eye = extract_eye(shape, true);
                        auto right_eye = extract_eye(shape, false);
                        float left_ear = eye_aspect_ratio(left_eye);
                        float right_ear = eye_aspect_ratio(right_eye);
                        float ear = (left_ear + right_ear) / 2.0f;

                        // æ˜¾ç¤º EAR å€¼
                        cv::putText(display_frame, "EAR: " + std::to_string(ear).substr(0, 5), 
                                    cv::Point(face.x, face.y - 10),
                                    cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);

                        const float EAR_THRESHOLD = 0.25f;
                        const int EYES_CLOSED_FRAMES = 15;

                        if (ear < EAR_THRESHOLD) {
                            drowsiness_counter++;
                            if (drowsiness_counter >= EYES_CLOSED_FRAMES) {
                                cv::putText(display_frame, "DROWSINESS ALERT!", cv::Point(50, 120),
                                            cv::FONT_HERSHEY_SIMPLEX, 1.0, cv::Scalar(0, 0, 255), 2);
                            }
                        } else {
                            drowsiness_counter = 0;
                        }

                        // ç»˜åˆ¶çœ¼ç›å…³é”®ç‚¹å’Œè½®å»“
                        for (const auto& pt : left_eye) cv::circle(display_frame, pt, 2, cv::Scalar(0, 255, 0), -1);
                        for (const auto& pt : right_eye) cv::circle(display_frame, pt, 2, cv::Scalar(0, 255, 0), -1);
                        
                        for (int i = 0; i < 5; i++) {
                            cv::line(display_frame, left_eye[i], left_eye[i+1], cv::Scalar(255, 0, 0), 1);
                            cv::line(display_frame, right_eye[i], right_eye[i+1], cv::Scalar(255, 0, 0), 1);
                        }
                        cv::line(display_frame, left_eye[5], left_eye[0], cv::Scalar(255, 0, 0), 1);
                        cv::line(display_frame, right_eye[5], right_eye[0], cv::Scalar(255, 0, 0), 1);
                    } catch (std::exception& e) {
                        std::cerr << "âŒ å¤„ç†äººè„¸ç‰¹å¾ç‚¹æ—¶å‡ºé”™: " << e.what() << std::endl;
                    }
                }
            } catch (std::exception& e) {
                std::cerr << "âŒ å¤„ç†å¸§æ—¶å‡ºé”™: " << e.what() << std::endl;
            }
        } else {
            // å¦‚æœæ¨¡å‹æœªèƒ½åŠ è½½ï¼Œæ˜¾ç¤ºç®€å•è­¦å‘Š
            cv::putText(display_frame, "æ¨¡å‹æœªåŠ è½½å®Œå…¨ï¼Œä»…æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢", 
                       cv::Point(10, 90), cv::FONT_HERSHEY_SIMPLEX, 0.7, 
                       cv::Scalar(0, 0, 255), 2);
        }

        // æ›´æ–°æœ€æ–°å¸§å¹¶æ˜¾ç¤º
        {
            std::lock_guard<std::mutex> lock(frame_mutex);
            latest_frame = display_frame.clone();
        }
        
        // æ˜¾ç¤ºå›¾åƒ
        cv::imshow("æ‘„åƒå¤´æµ‹è¯•", display_frame);
    }
    
    // è·å–æœ€æ–°å¤„ç†è¿‡çš„å¸§
    cv::Mat getLatestFrame() {
        std::lock_guard<std::mutex> lock(frame_mutex);
        return latest_frame.clone();
    }

    // è·å–æ€»å¸§æ•°
    int getTotalFrames() const {
        return total_frames;
    }

private:
    dlib::shape_predictor predictor;
    cv::CascadeClassifier face_cascade;
    cv::Mat latest_frame;
    
    // FPSè®¡ç®—
    std::chrono::time_point<std::chrono::steady_clock> start_time;
    int frame_counter;
    int total_frames;
    float fps;
    time_t last_log_time;
    
    // æ¨¡å‹çŠ¶æ€
    bool dlib_loaded;
    bool haar_loaded;
    
    // ç–²åŠ³æ£€æµ‹
    int drowsiness_counter = 0;
};

// ä¿®æ”¹libcam2opencv.cppçš„å®ç°
// è¿™éƒ¨åˆ†éœ€è¦å•ç‹¬ç¼–è¯‘é“¾æ¥ï¼Œè¿™é‡Œåªæ˜¯ä¼ªä»£ç è¯´æ˜ä¿®æ”¹ç‚¹
/*
void Libcam2OpenCV::requestComplete(libcamera::Request *request) {
    static int request_counter = 0;
    request_counter++;
    
    std::cout << "===== è¯·æ±‚å®Œæˆ #" << request_counter << " =====" << std::endl;
    
    if (nullptr == request) {
        std::cerr << "è¯·æ±‚æŒ‡é’ˆä¸ºç©º!" << std::endl;
        return;
    }
    
    if (request->status() == libcamera::Request::RequestCancelled) {
        std::cerr << "è¯·æ±‚è¢«å–æ¶ˆ!" << std::endl;
        return;
    }

    // å¤„ç†ç¼“å†²åŒº
    const libcamera::Request::BufferMap &buffers = request->buffers();
    std::cout << "ç¼“å†²åŒºæ•°é‡: " << buffers.size() << std::endl;
    
    for (auto bufferPair : buffers) {
        libcamera::FrameBuffer *buffer = bufferPair.second;
        libcamera::StreamConfiguration &streamConfig = config->at(0);
        unsigned int vw = streamConfig.size.width;
        unsigned int vh = streamConfig.size.height;
        unsigned int vstr = streamConfig.stride;
        
        std::cout << "å¤„ç†å¸§: " << vw << "x" << vh << ", stride=" << vstr << std::endl;
        
        auto mem = Mmap(buffer);
        if (mem.empty()) {
            std::cerr << "å†…å­˜æ˜ å°„ä¸ºç©º!" << std::endl;
            continue;
        }
        
        frame.create(vh, vw, CV_8UC3);
        uint ls = vw*3;
        uint8_t *ptr = mem[0].data();
        for (unsigned int i = 0; i < vh; i++, ptr += vstr) {
            memcpy(frame.ptr(i), ptr, ls);
        }
        
        if (nullptr != callback) {
            std::cout << "è°ƒç”¨å›è°ƒå‡½æ•°..." << std::endl;
            callback->hasFrame(frame, request->metadata());
        } else {
            std::cerr << "å›è°ƒä¸ºç©º!" << std::endl;
        }
    }

    // æ£€æŸ¥è¯·æ±‚çŠ¶æ€
    std::cout << "é‡æ–°å…¥é˜Ÿè¯·æ±‚..." << std::endl;
    try {
        if (request->status() == libcamera::Request::RequestCancelled) {
            std::cerr << "è¯·æ±‚åœ¨å¤„ç†è¿‡ç¨‹ä¸­è¢«å–æ¶ˆ!" << std::endl;
            return;
        }
        
        request->reuse(libcamera::Request::ReuseBuffers);
        int ret = camera->queueRequest(request);
        if (ret < 0) {
            std::cerr << "é‡æ–°å…¥é˜Ÿè¯·æ±‚å¤±è´¥: " << ret << std::endl;
        } else {
            std::cout << "è¯·æ±‚æˆåŠŸé‡æ–°å…¥é˜Ÿ" << std::endl;
        }
    } catch (const std::exception& e) {
        std::cerr << "é‡æ–°å…¥é˜Ÿè¯·æ±‚æ—¶å‘ç”Ÿå¼‚å¸¸: " << e.what() << std::endl;
    }
}
*/

// ä¸»å‡½æ•°
int main() {
    // æ³¨å†Œä¿¡å·å¤„ç†
    signal(SIGINT, signal_handler);
    signal(SIGTERM, signal_handler);
    
    try {
        std::cout << "=====================================" << std::endl;
        std::cout << "   ç–²åŠ³æ£€æµ‹ç³»ç»Ÿ - æ·±åº¦è°ƒè¯•ç‰ˆ" << std::endl;
        std::cout << "=====================================" << std::endl;
        
        std::cout << "ğŸ“· åˆå§‹åŒ–æ‘„åƒå¤´..." << std::endl;
        
        // åˆ›å»ºç›¸æœºå’Œå›è°ƒå¯¹è±¡
        Libcam2OpenCV cam;
        FatigueCallback callback;
        
        // æ³¨å†Œå›è°ƒ
        cam.registerCallback(&callback);

        // é…ç½®ç›¸æœº - ä½¿ç”¨æœ€ä½åˆ†è¾¨ç‡å¼€å§‹æµ‹è¯•
        Libcam2OpenCVSettings settings;
        settings.width = 320;     // æœ€ä½åˆ†è¾¨ç‡ä¾¿äºè°ƒè¯•
        settings.height = 240;
        settings.framerate = 15;  // ä½å¸§ç‡ä»¥å‡å°‘å¤„ç†è´Ÿæ‹…
        settings.brightness = 0.0;
        settings.contrast = 1.0;
        
        // å¯åŠ¨ç›¸æœº
        std::cout << "ğŸš€ å¯åŠ¨æ‘„åƒå¤´..." << std::endl;
        cam.start(settings);
        std::cout << "âœ… æ‘„åƒå¤´å·²å¯åŠ¨" << std::endl;
        
        // åˆ›å»ºç›‘è§†çº¿ç¨‹ï¼Œæ¯ç§’æ£€æŸ¥ä¸€æ¬¡å¸§æ›´æ–°æƒ…å†µ
        int last_frame_count = 0;
        std::thread monitor_thread([&]() {
            while (g_running) {
                std::this_thread::sleep_for(std::chrono::seconds(3));
                int current_frames = callback.getTotalFrames();
                if (current_frames == last_frame_count) {
                    std::cerr << "âš ï¸ è­¦å‘Š: 3ç§’å†…æ²¡æœ‰æ–°çš„å¸§!" << std::endl;
                } else {
                    std::cout << "âœ“ 3ç§’å†…æ”¶åˆ° " << (current_frames - last_frame_count) << " ä¸ªæ–°å¸§" << std::endl;
                }
                last_frame_count = current_frames;
            }
        });

        // ä¸»äº‹ä»¶å¾ªç¯
        std::cout << "ğŸ‘ï¸ å¼€å§‹æ£€æµ‹ (æŒ‰ 'q' æˆ– ESC é”®é€€å‡º)" << std::endl;
        
        while (g_running) {
            int key = cv::waitKey(30); // 30mså»¶è¿Ÿ
            
            if (key == 'q' || key == 27) { // 'q' æˆ– ESC é€€å‡º
                std::cout << "â¹ï¸ ç”¨æˆ·è¯·æ±‚é€€å‡º..." << std::endl;
                g_running = false;
                break;
            }
        }
        
        std::cout << "ğŸ›‘ æ­£åœ¨åœæ­¢æ‘„åƒå¤´..." << std::endl;
        cam.stop();
        
        // ç­‰å¾…ç›‘è§†çº¿ç¨‹ç»“æŸ
        if (monitor_thread.joinable()) {
            monitor_thread.join();
        }
        
        std::cout << "âœ… ç¨‹åºå·²å®‰å…¨é€€å‡º" << std::endl;
        return 0;
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ ç¨‹åºå‘ç”Ÿè‡´å‘½é”™è¯¯: " << e.what() << std::endl;
        return 1;
    }
}